{
  "embedder": "sentence-t5-base",
  "config": {
    "type": "sentence-sentence-t5-base",
    "dim": 768,
    "description": "T5-based sentence-transformer"
  },
  "projection_mode": "native",
  "use_projection": false,
  "clustering": {
    "embedder": "sentence-t5-base",
    "n_samples": 1520,
    "n_clusters": 10,
    "silhouette_score": 0.17258372902870178,
    "adjusted_rand_index": 0.6326196308945592,
    "avg_intra_cluster_similarity": 0.6912924647331238,
    "avg_inter_cluster_similarity": 0.745239794254303,
    "cluster_separation": -0.0539473295211792
  },
  "classification": {
    "embedder": "sentence-t5-base",
    "n_samples": 1520,
    "dataset_classification": {
      "cv_accuracy_mean": 0.9986842105263157,
      "cv_accuracy_std": 0.0016115064097257665,
      "test_accuracy": 1.0,
      "test_f1": 1.0
    },
    "tool_classification": {
      "cv_accuracy_mean": 0.6782894736842106,
      "cv_accuracy_std": 0.21201570200043401,
      "test_accuracy": 0.743421052631579,
      "test_f1": 0.7251326648837533
    },
    "average_accuracy": 0.8717105263157895,
    "average_f1": 0.8625663324418766
  },
  "complexity": {
    "embedder": "sentence-t5-base",
    "n_samples": 1520,
    "regression": {
      "train_mse": 0.007986040644484917,
      "test_mse": 0.010110861086048238,
      "train_r2": 0.8897662458119582,
      "test_r2": 0.8652584168265559
    },
    "ranking": {
      "spearman_train": 0.9404472361655514,
      "spearman_test": 0.928739372915115,
      "pearson_test": 0.9306621876565139,
      "ranking_accuracy_train": 0.8898026315789473,
      "ranking_accuracy_test": 0.8816440854611777
    },
    "complexity_score": 0.8969988948708354
  },
  "retrieval": {
    "embedder": "sentence-t5-base",
    "n_samples": 1520,
    "n_queries_evaluated": 100,
    "within_dataset": {
      "recall_at_k_mean": 0.010020040080160317,
      "recall_at_k_std": 3.469446951953614e-18,
      "ndcg_at_k_mean": 1.0,
      "ndcg_at_k_std": 0.0
    },
    "cross_dataset": {
      "recall_at_k_mean": 0.0,
      "recall_at_k_std": 0.0,
      "ndcg_at_k_mean": 0.0,
      "ndcg_at_k_std": 0.0
    },
    "combined_retrieval_score": 0.25250501002004005
  },
  "decision_prediction": {
    "embedder": "sentence-t5-base",
    "n_samples": 1520,
    "workflow_prediction": {
      "accuracy": 0.756578947368421,
      "f1": 0.7444383675837135
    },
    "tool_prediction": {
      "accuracy": 0.7269736842105263,
      "f1": 0.6816838291380625
    },
    "budget_prediction": {
      "accuracy": 0.9013157894736842,
      "f1": 0.9015359680240557
    },
    "combined_accuracy": 0.5427631578947368,
    "average_accuracy": 0.7949561403508771,
    "decision_score": 0.731907894736842
  },
  "total_time_seconds": 47.565781116485596
}