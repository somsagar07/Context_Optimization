[
  {
    "embedder": "metaclip-h14",
    "config": {
      "type": "metaclip-facebook/metaclip-h14-fullcc2.5b",
      "dim": 1024,
      "description": "MetaCLIP H14 - trained on 2.5B CommonCrawl data points"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03308588266372681,
      "adjusted_rand_index": 0.35971074494518307,
      "avg_intra_cluster_similarity": 0.6861298084259033,
      "avg_inter_cluster_similarity": 0.7806674242019653,
      "cluster_separation": -0.09453761577606201
    },
    "classification": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9875,
        "cv_accuracy_std": 0.005263157894736864,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.9858106698889464
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6572368421052632,
        "cv_accuracy_std": 0.1972741002694452,
        "test_accuracy": 0.7006578947368421,
        "test_f1": 0.6742273856565091
      },
      "average_accuracy": 0.84375,
      "average_f1": 0.8300190277727277
    },
    "complexity": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010756332856974485,
        "test_mse": 0.01540997534006497,
        "train_r2": 0.8515270576616307,
        "test_r2": 0.7946401937171091
      },
      "ranking": {
        "spearman_train": 0.9131713883700309,
        "spearman_test": 0.8748552495000402,
        "pearson_test": 0.8917793420387573,
        "ranking_accuracy_train": 0.8647295321637427,
        "ranking_accuracy_test": 0.8357000173701581
      },
      "complexity_score": 0.8347477216085747
    },
    "decision_prediction": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7302631578947368,
        "f1": 0.7176751950828486
      },
      "tool_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.6597121076960506
      },
      "budget_prediction": {
        "accuracy": 0.8782894736842105,
        "f1": 0.8789033024246887
      },
      "combined_accuracy": 0.4769736842105263,
      "average_accuracy": 0.7708333333333334,
      "decision_score": 0.6973684210526316
    },
    "total_time_seconds": 57.64525127410889
  },
  {
    "embedder": "jina-clip-v2",
    "config": {
      "type": "jina-clip-v2",
      "dim": 1024,
      "description": "Jina CLIP v2 - multilingual multimodal (supports 89 languages, 8192 tokens)"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03483957052230835,
      "adjusted_rand_index": 0.4101807648556727,
      "avg_intra_cluster_similarity": 0.39361974596977234,
      "avg_inter_cluster_similarity": 0.46335673332214355,
      "cluster_separation": -0.06973698735237122
    },
    "classification": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9894736842105262,
        "cv_accuracy_std": 0.006709236202095775,
        "test_accuracy": 0.9901315789473685,
        "test_f1": 0.9872439719989629
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6546052631578947,
        "cv_accuracy_std": 0.20278744859453016,
        "test_accuracy": 0.7105263157894737,
        "test_f1": 0.6810861158272024
      },
      "average_accuracy": 0.850328947368421,
      "average_f1": 0.8341650439130825
    },
    "complexity": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010956657281995283,
        "test_mse": 0.014629705656359545,
        "train_r2": 0.8487619185384215,
        "test_r2": 0.8050383953727311
      },
      "ranking": {
        "spearman_train": 0.9137307880327499,
        "spearman_test": 0.8960020582380419,
        "pearson_test": 0.898419545095099,
        "ranking_accuracy_train": 0.8658327918561837,
        "ranking_accuracy_test": 0.852375369115859
      },
      "complexity_score": 0.8505202268053865
    },
    "decision_prediction": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6743421052631579,
        "f1": 0.6418200209908921
      },
      "tool_prediction": {
        "accuracy": 0.7171052631578947,
        "f1": 0.6730648762466287
      },
      "budget_prediction": {
        "accuracy": 0.875,
        "f1": 0.8753822620003545
      },
      "combined_accuracy": 0.4375,
      "average_accuracy": 0.7554824561403509,
      "decision_score": 0.6759868421052632
    },
    "total_time_seconds": 239.49060344696045
  },
  {
    "embedder": "flava-full",
    "config": {
      "type": "flava-full",
      "dim": 768,
      "description": "FLAVA full model - unified vision-language model"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.04414842650294304,
      "adjusted_rand_index": 0.3225930604578572,
      "avg_intra_cluster_similarity": 0.906384289264679,
      "avg_inter_cluster_similarity": 0.8952834010124207,
      "cluster_separation": 0.0111008882522583
    },
    "classification": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9822368421052632,
        "cv_accuracy_std": 0.003354618101047867,
        "test_accuracy": 0.9901315789473685,
        "test_f1": 0.9899363089018263
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6657894736842105,
        "cv_accuracy_std": 0.21388763974964314,
        "test_accuracy": 0.694078947368421,
        "test_f1": 0.6566755612808244
      },
      "average_accuracy": 0.8421052631578947,
      "average_f1": 0.8233059350913253
    },
    "complexity": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.013552656955123728,
        "test_mse": 0.015459587970250687,
        "train_r2": 0.8129285434556761,
        "test_r2": 0.7939790349612197
      },
      "ranking": {
        "spearman_train": 0.8953203371753313,
        "spearman_test": 0.8870707420941215,
        "pearson_test": 0.8917193779001904,
        "ranking_accuracy_train": 0.8513293264024259,
        "ranking_accuracy_test": 0.8462958137919055
      },
      "complexity_score": 0.8405248885276706
    },
    "decision_prediction": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6710526315789473,
        "f1": 0.5826080796916904
      },
      "tool_prediction": {
        "accuracy": 0.6743421052631579,
        "f1": 0.6340800019958541
      },
      "budget_prediction": {
        "accuracy": 0.8651315789473685,
        "f1": 0.8664052841042618
      },
      "combined_accuracy": 0.3848684210526316,
      "average_accuracy": 0.736842105263158,
      "decision_score": 0.6488486842105263
    },
    "total_time_seconds": 32.130419969558716
  },
  {
    "embedder": "siglip-base",
    "config": {
      "type": "siglip-google/siglip-base-patch16-224",
      "dim": 768,
      "description": "SigLIP base patch16-224"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03069348819553852,
      "adjusted_rand_index": 0.2982393311795112,
      "avg_intra_cluster_similarity": 0.6801223754882812,
      "avg_inter_cluster_similarity": 0.6924616694450378,
      "cluster_separation": -0.012339293956756592
    },
    "classification": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9592105263157894,
        "cv_accuracy_std": 0.015512929108620522,
        "test_accuracy": 0.9572368421052632,
        "test_f1": 0.9570061147064095
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6697368421052632,
        "cv_accuracy_std": 0.2043353694623043,
        "test_accuracy": 0.6644736842105263,
        "test_f1": 0.6278571705201192
      },
      "average_accuracy": 0.8108552631578947,
      "average_f1": 0.7924316426132644
    },
    "complexity": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010730313397312282,
        "test_mse": 0.015351468860548457,
        "train_r2": 0.8518862121974256,
        "test_r2": 0.7954198756461623
      },
      "ranking": {
        "spearman_train": 0.9164596477772827,
        "spearman_test": 0.8740641705010963,
        "pearson_test": 0.8920775591110568,
        "ranking_accuracy_train": 0.8688853692874161,
        "ranking_accuracy_test": 0.8398037172138266
      },
      "complexity_score": 0.8347420230736293
    },
    "decision_prediction": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.75,
        "f1": 0.7454819999080519
      },
      "tool_prediction": {
        "accuracy": 0.694078947368421,
        "f1": 0.6501138976605296
      },
      "budget_prediction": {
        "accuracy": 0.8881578947368421,
        "f1": 0.8885824739283447
      },
      "combined_accuracy": 0.5230263157894737,
      "average_accuracy": 0.7774122807017544,
      "decision_score": 0.7138157894736843
    },
    "total_time_seconds": 28.67765212059021
  },
  {
    "embedder": "siglip-large",
    "config": {
      "type": "siglip-google/siglip-large-patch16-384",
      "dim": 1024,
      "description": "SigLIP large patch16-384"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.04716136306524277,
      "adjusted_rand_index": 0.380392416706564,
      "avg_intra_cluster_similarity": 0.6418241262435913,
      "avg_inter_cluster_similarity": 0.6135432124137878,
      "cluster_separation": 0.028280913829803467
    },
    "classification": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9289473684210527,
        "cv_accuracy_std": 0.012925580726571358,
        "test_accuracy": 0.9046052631578947,
        "test_f1": 0.9021239612986761
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6710526315789472,
        "cv_accuracy_std": 0.21446762987902854,
        "test_accuracy": 0.6677631578947368,
        "test_f1": 0.6297158983630385
      },
      "average_accuracy": 0.7861842105263157,
      "average_f1": 0.7659199298308573
    },
    "complexity": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010798198448519852,
        "test_mse": 0.016367604957863782,
        "train_r2": 0.8509491741355136,
        "test_r2": 0.781878419057378
      },
      "ranking": {
        "spearman_train": 0.9135877064001696,
        "spearman_test": 0.8756163633853877,
        "pearson_test": 0.8843680558290974,
        "ranking_accuracy_train": 0.8677239008013862,
        "ranking_accuracy_test": 0.8405419489317353
      },
      "complexity_score": 0.8287473912213829
    },
    "decision_prediction": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7598684210526315,
        "f1": 0.7580869969400823
      },
      "tool_prediction": {
        "accuracy": 0.694078947368421,
        "f1": 0.6501138976605296
      },
      "budget_prediction": {
        "accuracy": 0.8782894736842105,
        "f1": 0.8791824725581139
      },
      "combined_accuracy": 0.506578947368421,
      "average_accuracy": 0.7774122807017544,
      "decision_score": 0.709703947368421
    },
    "total_time_seconds": 49.62790656089783
  },
  {
    "embedder": "clip-base",
    "config": {
      "type": "clip-ViT-B/32",
      "dim": 512,
      "description": "CLIP base ViT-B/32"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03159257769584656,
      "adjusted_rand_index": 0.2852717363730418,
      "avg_intra_cluster_similarity": 0.7066004872322083,
      "avg_inter_cluster_similarity": 0.8461389541625977,
      "cluster_separation": -0.1395384669303894
    },
    "classification": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9789473684210526,
        "cv_accuracy_std": 0.003354618101047867,
        "test_accuracy": 0.9802631578947368,
        "test_f1": 0.9738132094943239
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6414473684210527,
        "cv_accuracy_std": 0.22078225946434832,
        "test_accuracy": 0.6776315789473685,
        "test_f1": 0.6408523834839626
      },
      "average_accuracy": 0.8289473684210527,
      "average_f1": 0.8073327964891432
    },
    "complexity": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.011000384522209616,
        "test_mse": 0.015070694542341967,
        "train_r2": 0.8481583381080569,
        "test_r2": 0.7991615921852008
      },
      "ranking": {
        "spearman_train": 0.9145610433559004,
        "spearman_test": 0.8872824242180272,
        "pearson_test": 0.8946546164974649,
        "ranking_accuracy_train": 0.8654320987654321,
        "ranking_accuracy_test": 0.8448410630536738
      },
      "complexity_score": 0.843222008201614
    },
    "decision_prediction": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6973684210526315,
        "f1": 0.6309569515791287
      },
      "tool_prediction": {
        "accuracy": 0.7006578947368421,
        "f1": 0.6575101049959826
      },
      "budget_prediction": {
        "accuracy": 0.8914473684210527,
        "f1": 0.8917009460365528
      },
      "combined_accuracy": 0.4144736842105263,
      "average_accuracy": 0.7631578947368421,
      "decision_score": 0.6759868421052633
    },
    "total_time_seconds": 28.69493293762207
  },
  {
    "embedder": "clip-large",
    "config": {
      "type": "clip-ViT-L/14",
      "dim": 768,
      "description": "CLIP large ViT-L/14"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.027404317632317543,
      "adjusted_rand_index": 0.32109484526901044,
      "avg_intra_cluster_similarity": 0.5568503141403198,
      "avg_inter_cluster_similarity": 0.7063295841217041,
      "cluster_separation": -0.14947926998138428
    },
    "classification": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9822368421052632,
        "cv_accuracy_std": 0.002631578947368407,
        "test_accuracy": 0.9835526315789473,
        "test_f1": 0.9770711518889865
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6453947368421054,
        "cv_accuracy_std": 0.21902460998342937,
        "test_accuracy": 0.6578947368421053,
        "test_f1": 0.6237411095305833
      },
      "average_accuracy": 0.8207236842105263,
      "average_f1": 0.800406130709785
    },
    "complexity": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.011505923648601825,
        "test_mse": 0.016490103214097624,
        "train_r2": 0.8411802273931257,
        "test_r2": 0.7802459558239834
      },
      "ranking": {
        "spearman_train": 0.9096606470720309,
        "spearman_test": 0.8776529209273117,
        "pearson_test": 0.8836703423194461,
        "ranking_accuracy_train": 0.860622427983539,
        "ranking_accuracy_test": 0.8391740489838457
      },
      "complexity_score": 0.8289494383756475
    },
    "decision_prediction": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7006578947368421,
        "f1": 0.6853361660272128
      },
      "tool_prediction": {
        "accuracy": 0.694078947368421,
        "f1": 0.6523956491988367
      },
      "budget_prediction": {
        "accuracy": 0.8914473684210527,
        "f1": 0.8915906045285081
      },
      "combined_accuracy": 0.5032894736842105,
      "average_accuracy": 0.7620614035087719,
      "decision_score": 0.6973684210526316
    },
    "total_time_seconds": 31.269842386245728
  },
  {
    "embedder": "clip-base-patch16",
    "config": {
      "type": "clip-ViT-B/16",
      "dim": 512,
      "description": "CLIP base ViT-B/16"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03277773782610893,
      "adjusted_rand_index": 0.34126568337659685,
      "avg_intra_cluster_similarity": 0.686321496963501,
      "avg_inter_cluster_similarity": 0.852296769618988,
      "cluster_separation": -0.16597527265548706
    },
    "classification": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9796052631578946,
        "cv_accuracy_std": 0.0038361525623982033,
        "test_accuracy": 0.9802631578947368,
        "test_f1": 0.9737980437454935
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6592105263157894,
        "cv_accuracy_std": 0.20216324894593657,
        "test_accuracy": 0.6842105263157895,
        "test_f1": 0.6477455327096514
      },
      "average_accuracy": 0.8322368421052632,
      "average_f1": 0.8107717882275725
    },
    "complexity": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010898425156848471,
        "test_mse": 0.01500567689626226,
        "train_r2": 0.8495657143184636,
        "test_r2": 0.8000280446557109
      },
      "ranking": {
        "spearman_train": 0.9153322450296153,
        "spearman_test": 0.8896929035703287,
        "pearson_test": 0.8947843985986502,
        "ranking_accuracy_train": 0.86647579597141,
        "ranking_accuracy_test": 0.8470557582073996
      },
      "complexity_score": 0.8448604741130198
    },
    "decision_prediction": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.6458779661479054
      },
      "tool_prediction": {
        "accuracy": 0.7105263157894737,
        "f1": 0.666986161524501
      },
      "budget_prediction": {
        "accuracy": 0.8914473684210527,
        "f1": 0.8917013998093932
      },
      "combined_accuracy": 0.4309210526315789,
      "average_accuracy": 0.768640350877193,
      "decision_score": 0.6842105263157894
    },
    "total_time_seconds": 29.057187795639038
  },
  {
    "embedder": "all-MiniLM-L6-v2",
    "config": {
      "type": "sentence-all-MiniLM-L6-v2",
      "dim": 384,
      "description": "Fast, lightweight sentence-transformer"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03676914423704147,
      "adjusted_rand_index": 0.32527125762139036,
      "avg_intra_cluster_similarity": 0.2868795394897461,
      "avg_inter_cluster_similarity": 0.18304479122161865,
      "cluster_separation": 0.10383474826812744
    },
    "classification": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9875,
        "cv_accuracy_std": 0.0038361525623982493,
        "test_accuracy": 0.9736842105263158,
        "test_f1": 0.9673135276664485
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6335526315789475,
        "cv_accuracy_std": 0.19994588949453743,
        "test_accuracy": 0.6743421052631579,
        "test_f1": 0.6505190605125041
      },
      "average_accuracy": 0.8240131578947368,
      "average_f1": 0.8089162940894763
    },
    "complexity": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.013777224391456165,
        "test_mse": 0.017724512275429993,
        "train_r2": 0.8098287706549449,
        "test_r2": 0.7637957020036555
      },
      "ranking": {
        "spearman_train": 0.892165084736385,
        "spearman_test": 0.8754534815893391,
        "pearson_test": 0.8739726243778306,
        "ranking_accuracy_train": 0.8497549815897769,
        "ranking_accuracy_test": 0.8445153725898906
      },
      "complexity_score": 0.8196245917964973
    },
    "decision_prediction": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6875,
        "f1": 0.649513419469783
      },
      "tool_prediction": {
        "accuracy": 0.6875,
        "f1": 0.6457304000689986
      },
      "budget_prediction": {
        "accuracy": 0.8782894736842105,
        "f1": 0.8786626706557868
      },
      "combined_accuracy": 0.4901315789473684,
      "average_accuracy": 0.7510964912280702,
      "decision_score": 0.6858552631578948
    },
    "total_time_seconds": 28.348033905029297
  },
  {
    "embedder": "all-MiniLM-L12-v2",
    "config": {
      "type": "sentence-all-MiniLM-L12-v2",
      "dim": 384,
      "description": "Larger MiniLM variant"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03821514546871185,
      "adjusted_rand_index": 0.34640549063019777,
      "avg_intra_cluster_similarity": 0.3240077793598175,
      "avg_inter_cluster_similarity": 0.25430479645729065,
      "cluster_separation": 0.06970298290252686
    },
    "classification": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9861842105263158,
        "cv_accuracy_std": 0.0024616167018249842,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.9803442600324795
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6368421052631579,
        "cv_accuracy_std": 0.19500337378997748,
        "test_accuracy": 0.6907894736842105,
        "test_f1": 0.6701038559422489
      },
      "average_accuracy": 0.8388157894736842,
      "average_f1": 0.8252240579873642
    },
    "complexity": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.012855148427735826,
        "test_mse": 0.01803476403205786,
        "train_r2": 0.8225564663495121,
        "test_r2": 0.7596611567345029
      },
      "ranking": {
        "spearman_train": 0.9020798684690018,
        "spearman_test": 0.8776054048186089,
        "pearson_test": 0.8720584135883245,
        "ranking_accuracy_train": 0.8551995343296512,
        "ranking_accuracy_test": 0.8402813965607087
      },
      "complexity_score": 0.818633280776556
    },
    "decision_prediction": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6677631578947368,
        "f1": 0.6289863093196654
      },
      "tool_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.6603364397860263
      },
      "budget_prediction": {
        "accuracy": 0.8782894736842105,
        "f1": 0.8787039888199346
      },
      "combined_accuracy": 0.4243421052631579,
      "average_accuracy": 0.75,
      "decision_score": 0.6685855263157895
    },
    "total_time_seconds": 35.58806753158569
  },
  {
    "embedder": "all-mpnet-base-v2",
    "config": {
      "type": "sentence-all-mpnet-base-v2",
      "dim": 768,
      "description": "Higher quality sentence-transformer"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.04006397724151611,
      "adjusted_rand_index": 0.3529931098598499,
      "avg_intra_cluster_similarity": 0.33700233697891235,
      "avg_inter_cluster_similarity": 0.27425920963287354,
      "cluster_separation": 0.06274312734603882
    },
    "classification": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9940789473684211,
        "cv_accuracy_std": 0.003223012819451533,
        "test_accuracy": 0.9967105263157895,
        "test_f1": 0.9964837466801333
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6302631578947369,
        "cv_accuracy_std": 0.2071020865134563,
        "test_accuracy": 0.6644736842105263,
        "test_f1": 0.6452305440835083
      },
      "average_accuracy": 0.830592105263158,
      "average_f1": 0.8208571453818208
    },
    "complexity": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.011295816339618158,
        "test_mse": 0.016402660159281355,
        "train_r2": 0.8440804026467554,
        "test_r2": 0.7814112587139345
      },
      "ranking": {
        "spearman_train": 0.911410719577804,
        "spearman_test": 0.8855279668169603,
        "pearson_test": 0.8844129721050962,
        "ranking_accuracy_train": 0.8649312324019927,
        "ranking_accuracy_test": 0.8499652596838632
      },
      "complexity_score": 0.8334696127654474
    },
    "decision_prediction": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6447368421052632,
        "f1": 0.6151283121940959
      },
      "tool_prediction": {
        "accuracy": 0.694078947368421,
        "f1": 0.6502616125044154
      },
      "budget_prediction": {
        "accuracy": 0.8881578947368421,
        "f1": 0.8870934986396372
      },
      "combined_accuracy": 0.41776315789473684,
      "average_accuracy": 0.7423245614035087,
      "decision_score": 0.6611842105263157
    },
    "total_time_seconds": 41.20269846916199
  },
  {
    "embedder": "sentence-t5-base",
    "config": {
      "type": "sentence-sentence-t5-base",
      "dim": 768,
      "description": "T5-based sentence-transformer"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.06244088336825371,
      "adjusted_rand_index": 0.4146391771853744,
      "avg_intra_cluster_similarity": 0.7135446071624756,
      "avg_inter_cluster_similarity": 0.7339109778404236,
      "cluster_separation": -0.020366370677947998
    },
    "classification": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9986842105263157,
        "cv_accuracy_std": 0.0016115064097257665,
        "test_accuracy": 1.0,
        "test_f1": 1.0
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6736842105263159,
        "cv_accuracy_std": 0.21088989985652667,
        "test_accuracy": 0.7105263157894737,
        "test_f1": 0.6953249601275917
      },
      "average_accuracy": 0.8552631578947368,
      "average_f1": 0.8476624800637959
    },
    "complexity": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.0089485258395772,
        "test_mse": 0.01112316432436713,
        "train_r2": 0.8764807691748335,
        "test_r2": 0.8517680385272333
      },
      "ranking": {
        "spearman_train": 0.9323456077851067,
        "spearman_test": 0.9203910922671694,
        "pearson_test": 0.9230921949236548,
        "ranking_accuracy_train": 0.8817183777344596,
        "ranking_accuracy_test": 0.8743051936772624
      },
      "complexity_score": 0.8860795653972013
    },
    "decision_prediction": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7368421052631579,
        "f1": 0.7078913095633688
      },
      "tool_prediction": {
        "accuracy": 0.7105263157894737,
        "f1": 0.6663051498239043
      },
      "budget_prediction": {
        "accuracy": 0.8848684210526315,
        "f1": 0.8849215321316478
      },
      "combined_accuracy": 0.5263157894736842,
      "average_accuracy": 0.7774122807017543,
      "decision_score": 0.7146381578947367
    },
    "total_time_seconds": 38.81816482543945
  },
  {
    "embedder": "e5-base",
    "config": {
      "type": "e5-intfloat/e5-base-v2",
      "dim": 768,
      "description": "E5 base model (modern embedding)"
    },
    "projection_mode": "projected",
    "use_projection": true,
    "clustering": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.033624909818172455,
      "adjusted_rand_index": 0.30076280891225704,
      "avg_intra_cluster_similarity": 0.8211383819580078,
      "avg_inter_cluster_similarity": 0.9207953810691833,
      "cluster_separation": -0.09965699911117554
    },
    "classification": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9868421052631579,
        "cv_accuracy_std": 0.0,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.980392156862745
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6572368421052632,
        "cv_accuracy_std": 0.2201481338349815,
        "test_accuracy": 0.6710526315789473,
        "test_f1": 0.647849352986531
      },
      "average_accuracy": 0.8289473684210527,
      "average_f1": 0.814120754924638
    },
    "complexity": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.01299960271228567,
        "test_mse": 0.018149873388842965,
        "train_r2": 0.8205625198116274,
        "test_r2": 0.7581271610798
      },
      "ranking": {
        "spearman_train": 0.8956650491864073,
        "spearman_test": 0.8615633672182726,
        "pearson_test": 0.8713618127891241,
        "ranking_accuracy_train": 0.8514010721247564,
        "ranking_accuracy_test": 0.8295336112558624
      },
      "complexity_score": 0.8098452641490363
    },
    "decision_prediction": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6578947368421053,
        "f1": 0.5514989902238698
      },
      "tool_prediction": {
        "accuracy": 0.6710526315789473,
        "f1": 0.6282302570530874
      },
      "budget_prediction": {
        "accuracy": 0.868421052631579,
        "f1": 0.868554873442212
      },
      "combined_accuracy": 0.3881578947368421,
      "average_accuracy": 0.7324561403508772,
      "decision_score": 0.6463815789473685
    },
    "total_time_seconds": 37.6823034286499
  },
  {
    "embedder": "metaclip-h14",
    "config": {
      "type": "metaclip-facebook/metaclip-h14-fullcc2.5b",
      "dim": 1024,
      "description": "MetaCLIP H14 - trained on 2.5B CommonCrawl data points"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.028210589662194252,
      "adjusted_rand_index": 0.3723624482484064,
      "avg_intra_cluster_similarity": 0.6766093969345093,
      "avg_inter_cluster_similarity": 0.7725902795791626,
      "cluster_separation": -0.09598088264465332
    },
    "classification": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9894736842105264,
        "cv_accuracy_std": 0.005659424517791215,
        "test_accuracy": 0.9901315789473685,
        "test_f1": 0.9890997420774253
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6644736842105263,
        "cv_accuracy_std": 0.20732558667942255,
        "test_accuracy": 0.7006578947368421,
        "test_f1": 0.670437500121879
      },
      "average_accuracy": 0.8453947368421053,
      "average_f1": 0.8297686210996522
    },
    "complexity": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.009331212796285822,
        "test_mse": 0.014485923319182204,
        "train_r2": 0.8711984244191854,
        "test_r2": 0.806954499211838
      },
      "ranking": {
        "spearman_train": 0.927830840759816,
        "spearman_test": 0.8846737470429386,
        "pearson_test": 0.8989970740652513,
        "ranking_accuracy_train": 0.8769344271171756,
        "ranking_accuracy_test": 0.845166753517457
      },
      "complexity_score": 0.8458141231273884
    },
    "decision_prediction": {
      "embedder": "metaclip-h14",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7368421052631579,
        "f1": 0.7341519891969854
      },
      "tool_prediction": {
        "accuracy": 0.7171052631578947,
        "f1": 0.6727669550775286
      },
      "budget_prediction": {
        "accuracy": 0.8947368421052632,
        "f1": 0.8952856759758454
      },
      "combined_accuracy": 0.5230263157894737,
      "average_accuracy": 0.7828947368421053,
      "decision_score": 0.7179276315789473
    },
    "total_time_seconds": 45.55831432342529
  },
  {
    "embedder": "jina-clip-v2",
    "config": {
      "type": "jina-clip-v2",
      "dim": 1024,
      "description": "Jina CLIP v2 - multilingual multimodal (supports 89 languages, 8192 tokens)"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.034295469522476196,
      "adjusted_rand_index": 0.3316262636400596,
      "avg_intra_cluster_similarity": 0.3924832344055176,
      "avg_inter_cluster_similarity": 0.453494131565094,
      "cluster_separation": -0.061010897159576416
    },
    "classification": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.993421052631579,
        "cv_accuracy_std": 0.0029421947072365497,
        "test_accuracy": 0.993421052631579,
        "test_f1": 0.992357130449887
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6625,
        "cv_accuracy_std": 0.2013695318702682,
        "test_accuracy": 0.7105263157894737,
        "test_f1": 0.6836341419130186
      },
      "average_accuracy": 0.8519736842105263,
      "average_f1": 0.8379956361814529
    },
    "complexity": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.009393308593553517,
        "test_mse": 0.013349334562532587,
        "train_r2": 0.8703412971947146,
        "test_r2": 0.8221011585502229
      },
      "ranking": {
        "spearman_train": 0.9265098894337026,
        "spearman_test": 0.9058503068580108,
        "pearson_test": 0.9075076735066969,
        "ranking_accuracy_train": 0.8760098548841239,
        "ranking_accuracy_test": 0.860495918012854
      },
      "complexity_score": 0.8639757327041169
    },
    "decision_prediction": {
      "embedder": "jina-clip-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7105263157894737,
        "f1": 0.7005116611609281
      },
      "tool_prediction": {
        "accuracy": 0.7138157894736842,
        "f1": 0.6681959833795015
      },
      "budget_prediction": {
        "accuracy": 0.881578947368421,
        "f1": 0.881578947368421
      },
      "combined_accuracy": 0.46710526315789475,
      "average_accuracy": 0.768640350877193,
      "decision_score": 0.6932565789473684
    },
    "total_time_seconds": 179.03990197181702
  },
  {
    "embedder": "flava-full",
    "config": {
      "type": "flava-full",
      "dim": 768,
      "description": "FLAVA full model - unified vision-language model"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.045322317630052567,
      "adjusted_rand_index": 0.3363858068240784,
      "avg_intra_cluster_similarity": 0.9127389192581177,
      "avg_inter_cluster_similarity": 0.9043903946876526,
      "cluster_separation": 0.008348524570465088
    },
    "classification": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9835526315789472,
        "cv_accuracy_std": 0.004160891658116266,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.9857937383747014
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6638157894736841,
        "cv_accuracy_std": 0.2162503102330729,
        "test_accuracy": 0.694078947368421,
        "test_f1": 0.6561870819539221
      },
      "average_accuracy": 0.8404605263157894,
      "average_f1": 0.8209904101643117
    },
    "complexity": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.012944943502893786,
        "test_mse": 0.015037848094504331,
        "train_r2": 0.82131699754602,
        "test_r2": 0.7995993177503729
      },
      "ranking": {
        "spearman_train": 0.9016909556656777,
        "spearman_test": 0.8894630283417394,
        "pearson_test": 0.8951111688332627,
        "ranking_accuracy_train": 0.8564205653021443,
        "ranking_accuracy_test": 0.8489881882925134
      },
      "complexity_score": 0.8445311730460561
    },
    "decision_prediction": {
      "embedder": "flava-full",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6743421052631579,
        "f1": 0.5869269625611186
      },
      "tool_prediction": {
        "accuracy": 0.6644736842105263,
        "f1": 0.6210258744105418
      },
      "budget_prediction": {
        "accuracy": 0.8848684210526315,
        "f1": 0.886072717011199
      },
      "combined_accuracy": 0.3782894736842105,
      "average_accuracy": 0.7412280701754385,
      "decision_score": 0.6504934210526315
    },
    "total_time_seconds": 33.01285004615784
  },
  {
    "embedder": "siglip-base",
    "config": {
      "type": "siglip-google/siglip-base-patch16-224",
      "dim": 768,
      "description": "SigLIP base patch16-224"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.02747684344649315,
      "adjusted_rand_index": 0.3201719593120628,
      "avg_intra_cluster_similarity": 0.6921842694282532,
      "avg_inter_cluster_similarity": 0.6811110377311707,
      "cluster_separation": 0.01107323169708252
    },
    "classification": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9618421052631578,
        "cv_accuracy_std": 0.017480697704719012,
        "test_accuracy": 0.9671052631578947,
        "test_f1": 0.9668777433721557
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6756578947368421,
        "cv_accuracy_std": 0.20405981619921548,
        "test_accuracy": 0.680921052631579,
        "test_f1": 0.6432817086658122
      },
      "average_accuracy": 0.8240131578947368,
      "average_f1": 0.8050797260189839
    },
    "complexity": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.009924494200519713,
        "test_mse": 0.01494548224909704,
        "train_r2": 0.8630091802880753,
        "test_r2": 0.8008302238161782
      },
      "ranking": {
        "spearman_train": 0.9246889766234768,
        "spearman_test": 0.8822814607953207,
        "pearson_test": 0.8949156641450393,
        "ranking_accuracy_train": 0.8760166233484947,
        "ranking_accuracy_test": 0.84607868681605
      },
      "complexity_score": 0.8415558423057494
    },
    "decision_prediction": {
      "embedder": "siglip-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.75,
        "f1": 0.7464924230613094
      },
      "tool_prediction": {
        "accuracy": 0.6710526315789473,
        "f1": 0.6265252446153202
      },
      "budget_prediction": {
        "accuracy": 0.8980263157894737,
        "f1": 0.8984745967355972
      },
      "combined_accuracy": 0.5131578947368421,
      "average_accuracy": 0.7730263157894738,
      "decision_score": 0.7080592105263158
    },
    "total_time_seconds": 29.130391597747803
  },
  {
    "embedder": "siglip-large",
    "config": {
      "type": "siglip-google/siglip-large-patch16-384",
      "dim": 1024,
      "description": "SigLIP large patch16-384"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.08251985907554626,
      "adjusted_rand_index": 0.36263053135069506,
      "avg_intra_cluster_similarity": 0.5938524007797241,
      "avg_inter_cluster_similarity": 0.5805616974830627,
      "cluster_separation": 0.013290703296661377
    },
    "classification": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9315789473684211,
        "cv_accuracy_std": 0.009624170288373538,
        "test_accuracy": 0.9144736842105263,
        "test_f1": 0.9119481536428166
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6697368421052632,
        "cv_accuracy_std": 0.21457456458609678,
        "test_accuracy": 0.6644736842105263,
        "test_f1": 0.626726617680565
      },
      "average_accuracy": 0.7894736842105263,
      "average_f1": 0.7693373856616907
    },
    "complexity": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.009897184178262356,
        "test_mse": 0.015678340472071138,
        "train_r2": 0.8633861488529004,
        "test_r2": 0.7910638472074178
      },
      "ranking": {
        "spearman_train": 0.9212112446469891,
        "spearman_test": 0.8811297302505919,
        "pearson_test": 0.8894782558660357,
        "ranking_accuracy_train": 0.8748727528698289,
        "ranking_accuracy_test": 0.8441245440333507
      },
      "complexity_score": 0.836096788729005
    },
    "decision_prediction": {
      "embedder": "siglip-large",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7861842105263158,
        "f1": 0.7846146118122602
      },
      "tool_prediction": {
        "accuracy": 0.6875,
        "f1": 0.6439903133339924
      },
      "budget_prediction": {
        "accuracy": 0.8881578947368421,
        "f1": 0.8886411630138451
      },
      "combined_accuracy": 0.5230263157894737,
      "average_accuracy": 0.787280701754386,
      "decision_score": 0.721217105263158
    },
    "total_time_seconds": 41.42915868759155
  },
  {
    "embedder": "clip-base",
    "config": {
      "type": "clip-ViT-B/32",
      "dim": 512,
      "description": "CLIP base ViT-B/32"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03159257769584656,
      "adjusted_rand_index": 0.2852717363730418,
      "avg_intra_cluster_similarity": 0.7066004872322083,
      "avg_inter_cluster_similarity": 0.8461389541625977,
      "cluster_separation": -0.1395384669303894
    },
    "classification": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9789473684210526,
        "cv_accuracy_std": 0.003354618101047867,
        "test_accuracy": 0.9802631578947368,
        "test_f1": 0.9738132094943239
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6414473684210527,
        "cv_accuracy_std": 0.22078225946434832,
        "test_accuracy": 0.6776315789473685,
        "test_f1": 0.6408523834839626
      },
      "average_accuracy": 0.8289473684210527,
      "average_f1": 0.8073327964891432
    },
    "complexity": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.011000384522209616,
        "test_mse": 0.015070694542341967,
        "train_r2": 0.8481583381080569,
        "test_r2": 0.7991615921852008
      },
      "ranking": {
        "spearman_train": 0.9145610433559004,
        "spearman_test": 0.8872824242180272,
        "pearson_test": 0.8946546164974649,
        "ranking_accuracy_train": 0.8654320987654321,
        "ranking_accuracy_test": 0.8448410630536738
      },
      "complexity_score": 0.843222008201614
    },
    "decision_prediction": {
      "embedder": "clip-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7171052631578947,
        "f1": 0.6976848299725548
      },
      "tool_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.6608552631578948
      },
      "budget_prediction": {
        "accuracy": 0.8980263157894737,
        "f1": 0.8981239391604247
      },
      "combined_accuracy": 0.48355263157894735,
      "average_accuracy": 0.7730263157894738,
      "decision_score": 0.7006578947368421
    },
    "total_time_seconds": 29.030963897705078
  },
  {
    "embedder": "clip-large",
    "config": {
      "type": "clip-ViT-L/14",
      "dim": 768,
      "description": "CLIP large ViT-L/14"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.027044527232646942,
      "adjusted_rand_index": 0.3397950363929671,
      "avg_intra_cluster_similarity": 0.5643686056137085,
      "avg_inter_cluster_similarity": 0.7389482259750366,
      "cluster_separation": -0.17457962036132812
    },
    "classification": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9855263157894738,
        "cv_accuracy_std": 0.00446205919942454,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.9839386963048229
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.650657894736842,
        "cv_accuracy_std": 0.2121075486359824,
        "test_accuracy": 0.6743421052631579,
        "test_f1": 0.6406484221418827
      },
      "average_accuracy": 0.8305921052631579,
      "average_f1": 0.8122935592233528
    },
    "complexity": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010149383859646104,
        "test_mse": 0.015645720225918675,
        "train_r2": 0.8599049597478641,
        "test_r2": 0.7914985583138888
      },
      "ranking": {
        "spearman_train": 0.9218697759299346,
        "spearman_test": 0.8819058266927378,
        "pearson_test": 0.8899558031137418,
        "ranking_accuracy_train": 0.8722601256226987,
        "ranking_accuracy_test": 0.8413018933472295
      },
      "complexity_score": 0.8367021925033133
    },
    "decision_prediction": {
      "embedder": "clip-large",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7335526315789473,
        "f1": 0.7224788980619523
      },
      "tool_prediction": {
        "accuracy": 0.7006578947368421,
        "f1": 0.6576585246360583
      },
      "budget_prediction": {
        "accuracy": 0.8881578947368421,
        "f1": 0.888825898611166
      },
      "combined_accuracy": 0.5131578947368421,
      "average_accuracy": 0.7741228070175438,
      "decision_score": 0.7088815789473684
    },
    "total_time_seconds": 41.08194589614868
  },
  {
    "embedder": "clip-base-patch16",
    "config": {
      "type": "clip-ViT-B/16",
      "dim": 512,
      "description": "CLIP base ViT-B/16"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03277773782610893,
      "adjusted_rand_index": 0.34126568337659685,
      "avg_intra_cluster_similarity": 0.686321496963501,
      "avg_inter_cluster_similarity": 0.852296769618988,
      "cluster_separation": -0.16597527265548706
    },
    "classification": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9796052631578946,
        "cv_accuracy_std": 0.0038361525623982033,
        "test_accuracy": 0.9802631578947368,
        "test_f1": 0.9737980437454935
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6592105263157894,
        "cv_accuracy_std": 0.20216324894593657,
        "test_accuracy": 0.6842105263157895,
        "test_f1": 0.6477455327096514
      },
      "average_accuracy": 0.8322368421052632,
      "average_f1": 0.8107717882275725
    },
    "complexity": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.010898425156848471,
        "test_mse": 0.01500567689626226,
        "train_r2": 0.8495657143184636,
        "test_r2": 0.8000280446557109
      },
      "ranking": {
        "spearman_train": 0.9153322450296153,
        "spearman_test": 0.8896929035703287,
        "pearson_test": 0.8947843985986502,
        "ranking_accuracy_train": 0.86647579597141,
        "ranking_accuracy_test": 0.8470557582073996
      },
      "complexity_score": 0.8448604741130198
    },
    "decision_prediction": {
      "embedder": "clip-base-patch16",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.6796794903130222
      },
      "tool_prediction": {
        "accuracy": 0.7171052631578947,
        "f1": 0.6727212051868803
      },
      "budget_prediction": {
        "accuracy": 0.8947368421052632,
        "f1": 0.8950632174730209
      },
      "combined_accuracy": 0.47368421052631576,
      "average_accuracy": 0.7719298245614036,
      "decision_score": 0.6973684210526316
    },
    "total_time_seconds": 28.639952659606934
  },
  {
    "embedder": "all-MiniLM-L6-v2",
    "config": {
      "type": "sentence-all-MiniLM-L6-v2",
      "dim": 384,
      "description": "Fast, lightweight sentence-transformer"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.03669043257832527,
      "adjusted_rand_index": 0.3278479427708754,
      "avg_intra_cluster_similarity": 0.2905624508857727,
      "avg_inter_cluster_similarity": 0.20705273747444153,
      "cluster_separation": 0.08350971341133118
    },
    "classification": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9901315789473685,
        "cv_accuracy_std": 0.002942194707236599,
        "test_accuracy": 0.9835526315789473,
        "test_f1": 0.9806815473930361
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6335526315789474,
        "cv_accuracy_std": 0.2014662320570864,
        "test_accuracy": 0.6546052631578947,
        "test_f1": 0.6234344432287668
      },
      "average_accuracy": 0.819078947368421,
      "average_f1": 0.8020579953109015
    },
    "complexity": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.012639341787412625,
        "test_mse": 0.01750877336230812,
        "train_r2": 0.8255353112115106,
        "test_r2": 0.7666707294082227
      },
      "ranking": {
        "spearman_train": 0.9025572363565323,
        "spearman_test": 0.8808240860919091,
        "pearson_test": 0.8756485099611365,
        "ranking_accuracy_train": 0.8573153562919644,
        "ranking_accuracy_test": 0.846512940767761
      },
      "complexity_score": 0.8237474077500659
    },
    "decision_prediction": {
      "embedder": "all-MiniLM-L6-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6414473684210527,
        "f1": 0.5433113532755288
      },
      "tool_prediction": {
        "accuracy": 0.680921052631579,
        "f1": 0.6400351173158795
      },
      "budget_prediction": {
        "accuracy": 0.8717105263157895,
        "f1": 0.8724434961918099
      },
      "combined_accuracy": 0.3881578947368421,
      "average_accuracy": 0.731359649122807,
      "decision_score": 0.6455592105263158
    },
    "total_time_seconds": 27.926206588745117
  },
  {
    "embedder": "all-MiniLM-L12-v2",
    "config": {
      "type": "sentence-all-MiniLM-L12-v2",
      "dim": 384,
      "description": "Larger MiniLM variant"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.0360863022506237,
      "adjusted_rand_index": 0.32267075886991803,
      "avg_intra_cluster_similarity": 0.3294968008995056,
      "avg_inter_cluster_similarity": 0.2779081165790558,
      "cluster_separation": 0.05158868432044983
    },
    "classification": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9888157894736842,
        "cv_accuracy_std": 0.001611506409725821,
        "test_accuracy": 0.9835526315789473,
        "test_f1": 0.9770551878440006
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6434210526315789,
        "cv_accuracy_std": 0.19637469131887061,
        "test_accuracy": 0.7039473684210527,
        "test_f1": 0.6858504740623058
      },
      "average_accuracy": 0.84375,
      "average_f1": 0.8314528309531533
    },
    "complexity": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.011828847690218957,
        "test_mse": 0.017146080283254993,
        "train_r2": 0.8367228083779075,
        "test_r2": 0.7715041297745974
      },
      "ranking": {
        "spearman_train": 0.9101346411340544,
        "spearman_test": 0.8880165695011379,
        "pearson_test": 0.8785147553610109,
        "ranking_accuracy_train": 0.8615307559021009,
        "ranking_accuracy_test": 0.8470123328122285
      },
      "complexity_score": 0.8297603496378676
    },
    "decision_prediction": {
      "embedder": "all-MiniLM-L12-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6348684210526315,
        "f1": 0.5468820887052437
      },
      "tool_prediction": {
        "accuracy": 0.7039473684210527,
        "f1": 0.661025346316684
      },
      "budget_prediction": {
        "accuracy": 0.8782894736842105,
        "f1": 0.8787039888199346
      },
      "combined_accuracy": 0.3980263157894737,
      "average_accuracy": 0.7390350877192983,
      "decision_score": 0.653782894736842
    },
    "total_time_seconds": 34.78188419342041
  },
  {
    "embedder": "all-mpnet-base-v2",
    "config": {
      "type": "sentence-all-mpnet-base-v2",
      "dim": 768,
      "description": "Higher quality sentence-transformer"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.04127185791730881,
      "adjusted_rand_index": 0.3371132064466915,
      "avg_intra_cluster_similarity": 0.33743342757225037,
      "avg_inter_cluster_similarity": 0.27385246753692627,
      "cluster_separation": 0.0635809600353241
    },
    "classification": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9953947368421053,
        "cv_accuracy_std": 0.003354618101047867,
        "test_accuracy": 0.993421052631579,
        "test_f1": 0.9923409269442264
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6322368421052632,
        "cv_accuracy_std": 0.217258717697386,
        "test_accuracy": 0.6710526315789473,
        "test_f1": 0.654646674156656
      },
      "average_accuracy": 0.8322368421052632,
      "average_f1": 0.8234938005504412
    },
    "complexity": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.00986902531308091,
        "test_mse": 0.015568911252606378,
        "train_r2": 0.8637748342554434,
        "test_r2": 0.7925221469655326
      },
      "ranking": {
        "spearman_train": 0.9248110663070646,
        "spearman_test": 0.8931977516784741,
        "pearson_test": 0.890609530634425,
        "ranking_accuracy_train": 0.8750054147714966,
        "ranking_accuracy_test": 0.8556322737536911
      },
      "complexity_score": 0.8428599493220034
    },
    "decision_prediction": {
      "embedder": "all-mpnet-base-v2",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6842105263157895,
        "f1": 0.6627853288059216
      },
      "tool_prediction": {
        "accuracy": 0.6973684210526315,
        "f1": 0.6530351466785972
      },
      "budget_prediction": {
        "accuracy": 0.8848684210526315,
        "f1": 0.8836289444197402
      },
      "combined_accuracy": 0.4605263157894737,
      "average_accuracy": 0.7554824561403509,
      "decision_score": 0.6817434210526316
    },
    "total_time_seconds": 43.27650451660156
  },
  {
    "embedder": "sentence-t5-base",
    "config": {
      "type": "sentence-sentence-t5-base",
      "dim": 768,
      "description": "T5-based sentence-transformer"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.17319633066654205,
      "adjusted_rand_index": 0.6327013909280056,
      "avg_intra_cluster_similarity": 0.6920023560523987,
      "avg_inter_cluster_similarity": 0.7446376085281372,
      "cluster_separation": -0.052635252475738525
    },
    "classification": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9986842105263157,
        "cv_accuracy_std": 0.0016115064097257665,
        "test_accuracy": 1.0,
        "test_f1": 1.0
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6782894736842106,
        "cv_accuracy_std": 0.21201570200043401,
        "test_accuracy": 0.743421052631579,
        "test_f1": 0.7251326648837533
      },
      "average_accuracy": 0.8717105263157895,
      "average_f1": 0.8625663324418766
    },
    "complexity": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.007986040644484917,
        "test_mse": 0.010110861086048238,
        "train_r2": 0.8897662458119582,
        "test_r2": 0.8652584168265559
      },
      "ranking": {
        "spearman_train": 0.9404472361655514,
        "spearman_test": 0.928739372915115,
        "pearson_test": 0.9306621876565139,
        "ranking_accuracy_train": 0.8898026315789473,
        "ranking_accuracy_test": 0.8816440854611777
      },
      "complexity_score": 0.8969988948708354
    },
    "decision_prediction": {
      "embedder": "sentence-t5-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.75,
        "f1": 0.7359299358534319
      },
      "tool_prediction": {
        "accuracy": 0.7236842105263158,
        "f1": 0.679195942973006
      },
      "budget_prediction": {
        "accuracy": 0.8980263157894737,
        "f1": 0.8984190879990783
      },
      "combined_accuracy": 0.5328947368421053,
      "average_accuracy": 0.7905701754385964,
      "decision_score": 0.7261513157894737
    },
    "total_time_seconds": 40.13535237312317
  },
  {
    "embedder": "e5-base",
    "config": {
      "type": "e5-intfloat/e5-base-v2",
      "dim": 768,
      "description": "E5 base model (modern embedding)"
    },
    "projection_mode": "native",
    "use_projection": false,
    "clustering": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "n_clusters": 10,
      "silhouette_score": 0.037559960037469864,
      "adjusted_rand_index": 0.32256917536886015,
      "avg_intra_cluster_similarity": 0.7805457711219788,
      "avg_inter_cluster_similarity": 0.902612566947937,
      "cluster_separation": -0.12206679582595825
    },
    "classification": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "dataset_classification": {
        "cv_accuracy_mean": 0.9861842105263158,
        "cv_accuracy_std": 0.0013157894736842036,
        "test_accuracy": 0.9868421052631579,
        "test_f1": 0.9803442600324795
      },
      "tool_classification": {
        "cv_accuracy_mean": 0.6532894736842105,
        "cv_accuracy_std": 0.23075698925198918,
        "test_accuracy": 0.6842105263157895,
        "test_f1": 0.6525729525485107
      },
      "average_accuracy": 0.8355263157894737,
      "average_f1": 0.816458606290495
    },
    "complexity": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "regression": {
        "train_mse": 0.01151976445035337,
        "test_mse": 0.016547038386196335,
        "train_r2": 0.8409891785860928,
        "test_r2": 0.7794872137978053
      },
      "ranking": {
        "spearman_train": 0.9129448037202174,
        "spearman_test": 0.8771503631649956,
        "pearson_test": 0.883796165159265,
        "ranking_accuracy_train": 0.8655972492960797,
        "ranking_accuracy_test": 0.8396300156331422
      },
      "complexity_score": 0.8283187884814005
    },
    "decision_prediction": {
      "embedder": "e5-base",
      "n_samples": 1520,
      "workflow_prediction": {
        "accuracy": 0.6513157894736842,
        "f1": 0.5381075234593942
      },
      "tool_prediction": {
        "accuracy": 0.680921052631579,
        "f1": 0.6375933645996178
      },
      "budget_prediction": {
        "accuracy": 0.8717105263157895,
        "f1": 0.8720664770567003
      },
      "combined_accuracy": 0.3782894736842105,
      "average_accuracy": 0.7346491228070176,
      "decision_score": 0.6455592105263158
    },
    "total_time_seconds": 37.93894648551941
  }
]