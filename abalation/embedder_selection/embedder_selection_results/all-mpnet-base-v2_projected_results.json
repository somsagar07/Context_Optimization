{
  "embedder": "all-mpnet-base-v2",
  "config": {
    "type": "sentence-all-mpnet-base-v2",
    "dim": 768,
    "description": "Higher quality sentence-transformer"
  },
  "projection_mode": "projected",
  "use_projection": true,
  "clustering": {
    "embedder": "all-mpnet-base-v2",
    "n_samples": 1520,
    "n_clusters": 10,
    "silhouette_score": 0.035901498049497604,
    "adjusted_rand_index": 0.3534475672535704,
    "avg_intra_cluster_similarity": 0.3377196192741394,
    "avg_inter_cluster_similarity": 0.27181461453437805,
    "cluster_separation": 0.06590500473976135
  },
  "classification": {
    "embedder": "all-mpnet-base-v2",
    "n_samples": 1520,
    "dataset_classification": {
      "cv_accuracy_mean": 0.9940789473684211,
      "cv_accuracy_std": 0.003223012819451533,
      "test_accuracy": 0.9967105263157895,
      "test_f1": 0.9964837466801333
    },
    "tool_classification": {
      "cv_accuracy_mean": 0.6302631578947369,
      "cv_accuracy_std": 0.2071020865134563,
      "test_accuracy": 0.6644736842105263,
      "test_f1": 0.6452305440835083
    },
    "average_accuracy": 0.830592105263158,
    "average_f1": 0.8208571453818208
  },
  "complexity": {
    "embedder": "all-mpnet-base-v2",
    "n_samples": 1520,
    "regression": {
      "train_mse": 0.011295816339618158,
      "test_mse": 0.016402660159281355,
      "train_r2": 0.8440804026467554,
      "test_r2": 0.7814112587139345
    },
    "ranking": {
      "spearman_train": 0.911410719577804,
      "spearman_test": 0.8855279668169603,
      "pearson_test": 0.8844129721050962,
      "ranking_accuracy_train": 0.8649312324019927,
      "ranking_accuracy_test": 0.8499652596838632
    },
    "complexity_score": 0.8334696127654474
  },
  "retrieval": {
    "embedder": "all-mpnet-base-v2",
    "n_samples": 1520,
    "n_queries_evaluated": 100,
    "within_dataset": {
      "recall_at_k_mean": 0.009979959919839678,
      "recall_at_k_std": 0.00039879255996257286,
      "ndcg_at_k_mean": 0.9994690242952597,
      "ndcg_at_k_std": 0.0052831415562538805
    },
    "cross_dataset": {
      "recall_at_k_mean": 4.9444980098395505e-05,
      "recall_at_k_std": 0.00048445988633255267,
      "ndcg_at_k_mean": 0.005882904319127012,
      "ndcg_at_k_std": 0.0576404551499059
    },
    "combined_retrieval_score": 0.2538453333785812
  },
  "decision_prediction": {
    "embedder": "all-mpnet-base-v2",
    "n_samples": 1520,
    "workflow_prediction": {
      "accuracy": 0.6381578947368421,
      "f1": 0.5625319411320308
    },
    "tool_prediction": {
      "accuracy": 0.6907894736842105,
      "f1": 0.6473833230307312
    },
    "budget_prediction": {
      "accuracy": 0.8848684210526315,
      "f1": 0.8842682498409992
    },
    "combined_accuracy": 0.3717105263157895,
    "average_accuracy": 0.7379385964912281,
    "decision_score": 0.6463815789473684
  },
  "total_time_seconds": 54.59767413139343
}